{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank and Linear Spectral Matrix Completion for Playlist Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import itertools\n",
    "import random\n",
    "import community\n",
    "import IPython.utils.path\n",
    "import cPickle as pickle \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['axes.edgecolor'] = 'grey'\n",
    "mpl.rcParams['grid.color'] = '#66CCCC'\n",
    "mpl.rcParams['text.color'] = '#0EBFE9'\n",
    "mpl.rcParams['xtick.color'] = '#66CCCC'\n",
    "mpl.rcParams['ytick.color'] = '#66CCCC'\n",
    "mpl.rcParams['axes.labelcolor'] = '#0EBFE9'\n",
    "\n",
    "import recog \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reload(sys)  # Reload does the trick!\n",
    "# sys.setdefaultencoding('UTF8')\n",
    "\n",
    "# pd.options.display.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.palettes import brewer\n",
    "bp.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mat(x, title, fig=(512, 200), cmap='Greys', reverse=False, nb_colors=9):\n",
    "    f1 = bp.figure(plot_width=fig[0], plot_height=fig[1], \n",
    "                   x_range=[0, x.shape[1]], y_range=[0, x.shape[0]])\n",
    "    \n",
    "\n",
    "    pal = brewer[cmap][nb_colors]\n",
    "    if reverse:\n",
    "        pal = pal[::-1]\n",
    "        \n",
    "    f1.image(image=[x], x=[0], y=[0], \n",
    "             dw=[x.shape[1]], dh=[x.shape[0]], palette=pal)\n",
    "    f1.title = title\n",
    "    f1.title_text_color = 'red'\n",
    "    f1.title_text_font_style = 'bold'\n",
    "    bp.show(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(IPython.utils.path.get_home_dir(), 'data/aotmv2/')\n",
    "DATA_DIR = os.path.join( IPython.utils.path.get_home_dir(), 'local/aotmv2/')\n",
    "print 'Data directory:', DATA_DIR\n",
    "\n",
    "DATASET_NAME = 'aotm'\n",
    "MAX_PROCESS = 8\n",
    "song_id_key = 'aotm_id'\n",
    "playlist_id_key = 'mix_id'\n",
    "playlist_cat_key = 'playlist_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FULL_SONGS = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_songs.h5'), 'data')\n",
    "FULL_SONGS.rename(columns={'temporal_echonest_features': 'ten'}, inplace=True)\n",
    "FULL_PLAYLISTS = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_playlists.h5'), 'data')\n",
    "FULL_MIXES = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_mixes.h5'), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features only from data\n",
    "to_remove = set(['title', 'artist_name', 'genre', 'top_genres', 'terms', \n",
    "                 'release', 'key', 'mode', 'genre_topics', 'genre_topic', 'ncut_id'])\n",
    "columns = set(FULL_SONGS.columns.tolist())\n",
    "feat_col = list(columns - to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create smaller dataset from AOTM data\n",
    "\n",
    "Here we remove ambiguous plyalist categories, we also verify that there are a sufficient number of playlists in each category. Each playlist is composed of \"popular songs\", (songs seen at least in a certain amount of playlists), and is not too short not too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min_playlists = 70\n",
    "min_playlists = 100\n",
    "# min_playlist_size = 8\n",
    "min_playlist_size = 5\n",
    "max_playlist_size = 20\n",
    "min_popularity = 5\n",
    "\n",
    "to_remove = ['Mixed Genre', 'Theme', 'Single Artist', 'Alternating DJ', 'Mixed', 'Cover', 'Narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove ambiguous categories\n",
    "FILT_MIXES = FULL_MIXES[~FULL_MIXES.playlist_category.isin(to_remove)]\n",
    "# Remove too short or too long playlists\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES['size'].between(min_playlist_size, max_playlist_size)]\n",
    "\n",
    "# Filter popular songs\n",
    "good_playlist_categories = np.unique(FILT_MIXES.playlist_category.values)\n",
    "FILT_PLAYLISTS = FULL_PLAYLISTS[FULL_PLAYLISTS[playlist_cat_key].isin(good_playlist_categories)]\n",
    "song_popularity_hist = FILT_PLAYLISTS.aotm_id.value_counts()\n",
    "good_songs = song_popularity_hist[song_popularity_hist >= min_popularity].index.values\n",
    "FILT_MIXES[song_id_key] = FILT_MIXES[song_id_key].apply(lambda x: list((set(x) & set(good_songs))))\n",
    "FILT_MIXES['size'] = FILT_MIXES[song_id_key].apply(len)\n",
    "\n",
    "# Refilter size of playlists\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES['size'].between(min_playlist_size, max_playlist_size)]\n",
    "# Keep a sufficient number of playlist in each category\n",
    "p_hist = FILT_MIXES[playlist_cat_key].value_counts()\n",
    "P_CATEGORIES = p_hist.index[np.where(p_hist > min_playlists)].values\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES[playlist_cat_key].isin(P_CATEGORIES)]\n",
    "\n",
    "# Update the list of valid songs since we removed some playlists\n",
    "good_songs = np.unique(list(itertools.chain(*list(FILT_MIXES[song_id_key].values))))\n",
    "FILT_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[playlist_id_key].isin(FILT_MIXES.index.values)]\n",
    "FILT_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[song_id_key].isin(good_songs)]\n",
    "\n",
    "# Keep only valid song and features in playlists\n",
    "FILT_SONGS = FULL_SONGS[FULL_SONGS.index.isin(good_songs)].sort('genre')\n",
    "FILT_FEAT = FILT_SONGS[feat_col]\n",
    "\n",
    "print 'Number of playlists:', len(FILT_MIXES)\n",
    "print 'Number of songs:', len(FILT_SONGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILT_MIXES[playlist_cat_key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create evenly sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_keep = ['Romantic', 'Depression', 'Break Up', 'Sleep',\n",
    "           'Punk', 'Country', 'Hip Hop', 'Dance/House', 'Rock', 'Rhythm and Blues']\n",
    "\n",
    "P_CATEGORIES = to_keep\n",
    "\n",
    "cat_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MINI_MIXES = FILT_MIXES[FILT_MIXES.playlist_category.isin(to_keep)]\n",
    "\n",
    "tmp = MINI_MIXES.reset_index().groupby(playlist_cat_key).agg({playlist_id_key: lambda x: random.sample(x, cat_size)})\n",
    "good_mixes = np.unique(list(itertools.chain(*list(tmp[playlist_id_key].values))))\n",
    "\n",
    "MINI_MIXES = MINI_MIXES[MINI_MIXES.index.isin(good_mixes)]\n",
    "# sample_idx = random.sample(MINI_MIXES.index, len(MINI_MIXES) // sample_factor)\n",
    "# MINI_MIXES = MINI_MIXES[MINI_MIXES.index.isin(sample_idx)]\n",
    "# Update the list of valid songs since we removed some playlists\n",
    "good_songs = np.unique(list(itertools.chain(*list(MINI_MIXES[song_id_key].values))))\n",
    "MINI_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[playlist_id_key].isin(MINI_MIXES.index.values)]\n",
    "MINI_PLAYLISTS = MINI_PLAYLISTS[MINI_PLAYLISTS[song_id_key].isin(good_songs)]\n",
    "\n",
    "# Keep only valid song and features in playlists\n",
    "MINI_SONGS = FILT_SONGS[FILT_SONGS.index.isin(good_songs)].sort('genre')\n",
    "MINI_FEAT = MINI_SONGS[feat_col]\n",
    "\n",
    "print 'Number of playlists:', len(MINI_MIXES)\n",
    "print 'Number of songs:', len(MINI_SONGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MINI_MIXES[playlist_cat_key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIXES = MINI_MIXES\n",
    "FEAT = MINI_FEAT\n",
    "PLAYLISTS = MINI_PLAYLISTS\n",
    "SONGS = MINI_SONGS\n",
    "DATASET_VERSION = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MIXES = FILT_MIXES\n",
    "# FEAT = FILT_FEAT\n",
    "# PLAYLISTS = FILT_PLAYLISTS\n",
    "# SONGS = FILT_SONGS\n",
    "# SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "# DATASET_VERSION = 'filt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DUMP_DIR = os.path.join(DATA_DIR, 'dump_' + DATASET_VERSION + '/')\n",
    "\n",
    "if not os.path.exists(DUMP_DIR):\n",
    "    os.mkdir(DUMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare graphs\n",
    "\n",
    "First, create train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixes_train_idx, mixes_test_idx = train_test_split(MIXES.index.values, train_size=train_set_size)\n",
    "mixes_train_idx, mixes_test_idx = sorted(mixes_train_idx), sorted(mixes_test_idx)\n",
    "\n",
    "MIXES_train = MIXES[MIXES.index.isin(mixes_train_idx)]\n",
    "MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]\n",
    "PLAYLISTS_train = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_train_idx)]\n",
    "\n",
    "songs_train_idx = np.unique(list(itertools.chain(*list(MIXES_train[song_id_key].values))))\n",
    "songs_test_idx = np.unique(list(itertools.chain(*list(MIXES_test[song_id_key].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create song graph\n",
    "\n",
    "To keep the same number of nodes, we create the full song graph and we remove edges not in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SONG_GRAPH, SONGS = recog.graph.create_song_graph(FEAT, SONGS, 5)\n",
    "SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "print nx.info(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_SONGS = nx.to_numpy_matrix(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample = W_SONGS[2300:3500, 2300:3500]\n",
    "sample = W_SONGS\n",
    "sample = (sample > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Song graph', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_song_graph_partitions_' + str(SONG_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute all shortest path between songs for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pairs_distance = nx.all_pairs_dijkstra_path_length(SONG_GRAPH, weight='dist')\n",
    "end = time.time()\n",
    "print 'Created in:', end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(pairs_distance, open(os.path.join(DUMP_DIR, 'song_pairs_distance.pickle'), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create playlist graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLAYLIST_GRAPH_train, MIXES_train, PLAYLISTS_train = recog.graph.create_playlist_graph(MIXES_train.copy(), PLAYLISTS_train, playlist_id_key, song_id_key, \n",
    "                                                       'playlist_category', 0.3, 0.2)\n",
    "print nx.info(PLAYLIST_GRAPH_train)\n",
    "\n",
    "PLAYLISTS_test = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_test_idx)]\n",
    "# MIXES_train = MIXES[MIXES.index.isin(mixes_train_idx)]\n",
    "# MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_PLAYLISTS = nx.to_numpy_matrix(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = (W_PLAYLISTS > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Playlist graph', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_playlist_graph_partitions_' + str(PLAYLIST_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playlist graph without categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripped_playlist_graph(g):\n",
    "    h = nx.Graph()\n",
    "    h.add_nodes_from(g.nodes(data=True))\n",
    "    counts = nx.get_edge_attributes(g, 'count')\n",
    "\n",
    "    cosine = lambda u, v, x: float(x) / (np.sqrt(g.node[u]['size']) * np.sqrt(g.node[v]['size']))\n",
    "    reweighted_attrs = [(k[0], k[1], cosine(k[0], k[1], v)) for k, v in counts.iteritems()]\n",
    "\n",
    "    h.add_weighted_edges_from(reweighted_attrs)\n",
    "\n",
    "    d = community.best_partition(h)\n",
    "    mod = community.modularity(d, h)\n",
    "    print 'Number of clusters: {}, Modularity: {}'.format(len(set(d.values())), mod)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_PLAYLISTS_train = nx.to_numpy_matrix(STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = (W_PLAYLISTS_train > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Playlist graph train', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_playlist_graph_train_partitions_' + str(PLAYLIST_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIXES_train.groupby('cluster_id')['playlist_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create C matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_train = recog.create_recommendation_matrix(MIXES_train, SONGS.index,\n",
    "                                     playlist_id_key, DATASET_NAME, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog.plot_factor_mat(C_train.toarray())\n",
    "# plot_mat(C_train.toarray(), 'C', (512, 512))\n",
    "print 'Sparsity ratio:', C_train.nnz / float(C_train.shape[0] * C_train.shape[1])\n",
    "print C_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump(outdir):\n",
    "    # Write graphs\n",
    "    nx.write_gpickle(SONG_GRAPH, os.path.join(outdir, 'song_graph.gpickle'))\n",
    "#     nx.write_gpickle(SONG_GRAPH_train, os.path.join(outdir, 'song_graph_train.gpickle'))\n",
    "#     nx.write_gpickle(PLAYLIST_GRAPH, os.path.join(outdir, 'playlist_graph.gpickle'))\n",
    "    nx.write_gpickle(PLAYLIST_GRAPH_train, os.path.join(outdir, 'playlist_graph_train.gpickle'))\n",
    "    \n",
    "    # Write data\n",
    "    store = pd.HDFStore(os.path.join(outdir, 'data.h5'))\n",
    "    store['songs'] = SONGS\n",
    "    store['mixes'] = MIXES\n",
    "    store['playlists'] = PLAYLISTS\n",
    "    store.close()\n",
    "\n",
    "    matlab_export_path = os.path.join(outdir, 'recog_real_data.mat')\n",
    "    matlab_data = dict()\n",
    "\n",
    "#     matlab_data['C'] = C\n",
    "    matlab_data['C_train'] = C_train\n",
    "#     matlab_data['songs_train'] = songs_train_idx.tolist()\n",
    "#     matlab_data['songs_test'] = songs_test_idx.tolist()\n",
    "    matlab_data['mixes_train'] = mixes_train_idx\n",
    "    matlab_data['mixes_test'] = mixes_test_idx\n",
    "\n",
    "    sp.io.savemat(matlab_export_path, matlab_data)\n",
    "    print 'Dump data to:', outdir\n",
    "    \n",
    "dump(DUMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(outdir):    \n",
    "    if not os.path.exists(outdir):\n",
    "        print 'Error folder does not exists'\n",
    "        return\n",
    "\n",
    "    song_graph = nx.read_gpickle(os.path.join(outdir, 'song_graph.gpickle'))\n",
    "    playlist_graph_train = nx.read_gpickle(os.path.join(outdir, 'playlist_graph_train.gpickle'))\n",
    "    \n",
    "    store = pd.HDFStore(os.path.join(outdir, 'data.h5'))\n",
    "    songs = store['songs']\n",
    "    mixes = store['mixes']\n",
    "    playlists = store['playlists']\n",
    "    store.close()\n",
    "\n",
    "    matlab_export_path = os.path.join(outdir, 'recog_real_data.mat')\n",
    "    data = sp.io.loadmat(matlab_export_path)\n",
    "    c_train = data['C_train']\n",
    "    mixes_train_idx = data['mixes_train'].tolist()[0]\n",
    "    mixes_test_idx = data['mixes_test'].tolist()[0]\n",
    "\n",
    "    return songs, mixes, playlists, song_graph, playlist_graph_train, c_train, mixes_train_idx, mixes_test_idx\n",
    "    \n",
    "\n",
    "DATASET_VERSION = 'medium'\n",
    "DUMP_DIR = os.path.join(DATA_DIR, 'dump_' + DATASET_VERSION + '/')\n",
    "    \n",
    "SONGS, MIXES, PLAYLISTS, SONG_GRAPH, PLAYLIST_GRAPH_train, C_train, mixes_train_idx, mixes_test_idx = load(DUMP_DIR)\n",
    "FEAT = SONGS[feat_col]\n",
    "SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]\n",
    "pairs_distance = None\n",
    "PLAYLISTS_train = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_train_idx)]\n",
    "PLAYLISTS_test = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_test_idx)]\n",
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if needed\n",
    "pairs_distance = pickle.load(open(os.path.join(DUMP_DIR, 'song_pairs_distance.pickle'), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rank = len(P_CATEGORIES)\n",
    "RANK = 10  # number of clusters of song graph; number of playlist categories\n",
    "PLAYLIST_SIZE = 10\n",
    "SAMPLE_SIZE = 3  # pick x songs as input from a playlist\n",
    "NB_SAMPLED_PLAYLISTS = 100  # playlist per categories for random and sampled case\n",
    "TOP_K_PLAYLISTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def agglomerate_results_per_category(data_path, key):\n",
    "    path = data_path + '.h5'\n",
    "    store = pd.HDFStore(path)\n",
    "    random = store['results_random'][key]\n",
    "    test_set = store['results_test'][key]\n",
    "    \n",
    "    sampled = None\n",
    "    if 'results_sampled' in store:\n",
    "        sampled = store['results_sampled'][key]\n",
    "    \n",
    "    res = pd.DataFrame(index=random.index)\n",
    "    res['Random'] = random\n",
    "    res['Test set'] = test_set\n",
    "    \n",
    "    if sampled is not None:\n",
    "        res['Sampled'] = sampled\n",
    "    store.close()\n",
    "    \n",
    "    res.index.name = 'Playlist category'\n",
    "    \n",
    "    out = data_path + '_agg_' + key + '.tex'\n",
    "    res.to_latex(out)\n",
    "    return res\n",
    "\n",
    "\n",
    "def training_closure():\n",
    "    def inner(data_path, theta_playlists, theta_songs, playlist_graph):  # stripped or normal\n",
    "        return recog.proximal_training(C_train, playlist_graph, SONG_GRAPH, RANK,\n",
    "                                       theta_tv_a=theta_playlists,\n",
    "                                       theta_tv_b=theta_songs,\n",
    "                                       data_path=data_path,\n",
    "                                       verbose=1)\n",
    "    return inner\n",
    "\n",
    "    \n",
    "def create_sampled_mix_df(playlist_df, playlist_size, nb_playlists, p_categories, do_random=True):\n",
    "    assert(playlist_size > 0)\n",
    "    mix_df = []\n",
    "    mix_id = 0\n",
    "    for cat, group in playlist_df.groupby('playlist_category'):\n",
    "        for i in xrange(nb_playlists):\n",
    "            mix_id += 1\n",
    "            if do_random:\n",
    "                size = min(playlist_size, len(playlist_df))\n",
    "                songs = list(np.random.choice(playlist_df[SONG_ID_KEY].values, size, replace=False))\n",
    "            else:\n",
    "                size = min(playlist_size, len(group))\n",
    "                songs = list(np.random.choice(group[SONG_ID_KEY].values, size, replace=False))\n",
    "\n",
    "            d = {'mix_id': mix_id, 'playlist_category': cat, SONG_ID_KEY: songs}\n",
    "            mix_df.append(d)\n",
    "        \n",
    "    mix_df = pd.DataFrame(mix_df).set_index('mix_id')\n",
    "    return mix_df\n",
    "\n",
    "\n",
    "def scores_from_mix_df(mix_df, song_df, reco_func, score_func, sample_size=0):    \n",
    "    results = []\n",
    "    for mix_id, row in mix_df.iterrows():\n",
    "        p_category = row['playlist_category']\n",
    "        songs = row[SONG_ID_KEY]\n",
    "        if sample_size > 0:\n",
    "            songs = np.random.choice(songs, min(sample_size, len(songs)), replace=False)\n",
    "        \n",
    "        reco_df = reco_func(songs)\n",
    "        input_df = song_df.loc[songs]\n",
    "        scores = score_func(reco_df, input_df, p_category)\n",
    "        scores['mix_id'] = mix_id\n",
    "        results.append(scores)\n",
    "    res = pd.DataFrame(results).set_index('mix_id')\n",
    "    return res.groupby('playlist_category').mean()\n",
    "\n",
    "\n",
    "\n",
    "def run_validation(data_path, A, B, method=0, sample_size=SAMPLE_SIZE, top_k_playlist=TOP_K_PLAYLISTS,\n",
    "                   score_playlist_cat_only=False,\n",
    "                   with_sampled_playlists=True, only_test_set=False):\n",
    "    \n",
    "    start = time.time()\n",
    "    # Select recommend method\n",
    "    reco_f = None\n",
    "    if method == 0:\n",
    "        reco_f = lambda x: recog.recommend(x, SONGS, A, B, PLAYLIST_SIZE, SONG_TO_IDX, top_k_playlist)\n",
    "    elif method == 1:\n",
    "        reco_f = lambda x: recog.recommend_playlist_graph_only(x, SONGS, MIXES_train,\n",
    "                                                               PLAYLISTS_train, \n",
    "                                                               SONG_ID_KEY,\n",
    "                                                               PLAYLIST_ID_KEY,\n",
    "                                                               top_k_playlists=top_k_playlist, \n",
    "                                                               top_k_songs=PLAYLIST_SIZE)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    # Select score func\n",
    "    score_func = lambda x, y, z: recog.recommend_score(x, y, z, \n",
    "                                                       'playlist_category', \n",
    "                                                       'cluster_id', PLAYLISTS_train,\n",
    "                                                        PLAYLIST_SIZE, SONG_TO_IDX, SONG_ID_KEY, \n",
    "                                                        PAIR_DISTANCES, score_playlist_cat_only)\n",
    "        \n",
    "    results_test = scores_from_mix_df(MIXES_test, SONGS, reco_f, score_func, sample_size)\n",
    "    if only_test_set:\n",
    "        print 'Validation took {} seconds'.format(time.time() - start)\n",
    "        return results_test\n",
    "    \n",
    "    random_mix = create_sampled_mix_df(PLAYLISTS_test, PLAYLIST_SIZE, NB_SAMPLED_PLAYLISTS, P_CATEGORIES)\n",
    "    results_random = scores_from_mix_df(random_mix, SONGS, reco_f, score_func, sample_size)\n",
    "    \n",
    "    # Dump results to disk\n",
    "    path = data_path + '.h5'\n",
    "    store = pd.HDFStore(path)\n",
    "    store['results_test'] = results_test\n",
    "    store['results_random'] = results_random\n",
    "    \n",
    "    # Concat results\n",
    "    res = [results_test.mean(), results_random.mean()]\n",
    "    cols = [(0, 'test_set'), (1, 'random')]\n",
    "\n",
    "    if with_sampled_playlists:\n",
    "        sampled_mix = create_sampled_mix_df(PLAYLISTS_test, PLAYLIST_SIZE, NB_SAMPLED_PLAYLISTS, P_CATEGORIES, False)\n",
    "        results_sampled = scores_from_mix_df(sampled_mix, SONGS, reco_f, score_func, sample_size)\n",
    "        store['results_sampled'] = results_sampled\n",
    "        res.append(results_sampled.mean())\n",
    "        cols.append([2, 'sampled'])\n",
    "\n",
    "    store.close()\n",
    "    \n",
    "    results = pd.concat(res, axis=1)\n",
    "    results.rename(columns=dict(cols), inplace=True)\n",
    "    \n",
    "    print 'Validation took {} seconds'.format(time.time() - start)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pairwise distance of song graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = nx.get_edge_attributes(SONG_GRAPH, 'dist')\n",
    "\n",
    "res = sum(map(lambda x: x[1], distances.items()))\n",
    "res /= len(distances)\n",
    "\n",
    "print 'Average distance on the song graph:', res\n",
    "    \n",
    "print 'Diameter:', nx.diameter(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Here we set theta_song to 0 and compare our model to the random case or using a simple playlist recommender system.\n",
    "\n",
    "We designed two scenarii with a playlist graph only created with cosine similarity, the second scenario also add the metadata.\n",
    "\n",
    "We test different cases:\n",
    "\n",
    "- NMF only $\\theta_p = \\theta_s = 0$\n",
    "- NMF + playlist graph compared to a different rec sys using only playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = os.path.join(DUMP_DIR, 'experiment1')\n",
    "if not os.path.exists(EXPERIMENT_DIR):\n",
    "    os.mkdir(EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_only = 0\n",
    "theta_songs_nmf_only = 0\n",
    "data_path = os.path.join(EXPERIMENT_DIR, 'nmf_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_only, B_nmf_only = training_closure()(data_path, \n",
    "                                            theta_playlists_nmf_only,\n",
    "                                            theta_songs_nmf_only, \n",
    "                                            STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 210.262040854 seconds\n"
     ]
    }
   ],
   "source": [
    "results_nmf_only = run_validation(data_path, A_nmf_only, B_nmf_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_set</th>\n",
       "      <th>random</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_cat_out</th>\n",
       "      <td>0.202775</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_cluster</th>\n",
       "      <td>-0.121288</td>\n",
       "      <td>-0.141333</td>\n",
       "      <td>-0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_genre</th>\n",
       "      <td>0.475764</td>\n",
       "      <td>0.435732</td>\n",
       "      <td>0.454768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_in</th>\n",
       "      <td>63.428459</td>\n",
       "      <td>63.477088</td>\n",
       "      <td>63.053262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_out</th>\n",
       "      <td>63.119911</td>\n",
       "      <td>63.275132</td>\n",
       "      <td>63.158809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   test_set     random    sampled\n",
       "p_cat_out          0.202775   0.123900   0.214700\n",
       "s_cluster         -0.121288  -0.141333  -0.132600\n",
       "s_genre            0.475764   0.435732   0.454768\n",
       "s_graph_dist_in   63.428459  63.477088  63.053262\n",
       "s_graph_dist_out  63.119911  63.275132  63.158809"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nmf_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1\n",
    "\n",
    "In this scenario no playlist categories are given, we create a playlist similarity graph only using cosine similarity. This is the normal case (Spotify, Deezer, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR = os.path.join(EXPERIMENT_DIR, 'scenario1')\n",
    "if not os.path.exists(SCENARIO_DIR):\n",
    "    os.mkdir(SCENARIO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playlist graph recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 25.4767649174 seconds\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(SCENARIO_DIR, 'playlist_graph_rec')\n",
    "exp1_s1_playlist_graph_rec = run_validation(data_path, None, None, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_set</th>\n",
       "      <th>random</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_cat_out</th>\n",
       "      <td>0.556469</td>\n",
       "      <td>0.131450</td>\n",
       "      <td>0.544247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_cluster</th>\n",
       "      <td>-0.173271</td>\n",
       "      <td>-0.161699</td>\n",
       "      <td>-0.179474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_genre</th>\n",
       "      <td>0.298235</td>\n",
       "      <td>0.337460</td>\n",
       "      <td>0.300272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_in</th>\n",
       "      <td>63.243423</td>\n",
       "      <td>63.633844</td>\n",
       "      <td>63.034306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_out</th>\n",
       "      <td>57.963167</td>\n",
       "      <td>59.036521</td>\n",
       "      <td>56.510832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   test_set     random    sampled\n",
       "p_cat_out          0.556469   0.131450   0.544247\n",
       "s_cluster         -0.173271  -0.161699  -0.179474\n",
       "s_genre            0.298235   0.337460   0.300272\n",
       "s_graph_dist_in   63.243423  63.633844  63.034306\n",
       "s_graph_dist_out  57.963167  59.036521  56.510832"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_s1_playlist_graph_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our recommender system\n",
    "\n",
    "Find best theta from grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_theta_playlist():\n",
    "    results = []\n",
    "    for theta in xrange(25, 50, 5):\n",
    "        d = {'theta_playlist': theta}\n",
    "        data_path = os.path.join(SCENARIO_DIR, 'exp1_s1_theta_p_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta, 0.0, STRIPPED_PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "def find_best_theta(all_data):\n",
    "    best_d = all_data[0]\n",
    "    old_score = 0\n",
    "    for d in all_data:\n",
    "        r = run_validation(d['data_path'], d['a'], d['b'], sample_size=0,\n",
    "                           with_sampled_playlists=False, score_playlist_cat_only=True, only_test_set=True)\n",
    "        score = r['p_cat_out'].mean()\n",
    "        if score > old_score:\n",
    "            print 'Theta: {}, score: {}'.format(d['theta_playlist'], score)\n",
    "            best_d = d\n",
    "            old_score = score\n",
    "    return best_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 27.9912080765 seconds\n",
      "Theta: 1, score: 0.240428759459\n",
      "Validation took 25.5831568241 seconds\n",
      "Theta: 4, score: 0.277753818739\n",
      "Validation took 25.9557518959 seconds\n",
      "Theta: 7, score: 0.395333404383\n",
      "Validation took 26.2310221195 seconds\n",
      "Theta: 10, score: 0.450928604442\n",
      "Validation took 25.836771965 seconds\n",
      "Validation took 25.8502099514 seconds\n",
      "Validation took 27.8938879967 seconds\n",
      "Validation took 27.0365109444 seconds\n",
      "Theta: 22, score: 0.470015354617\n",
      "Validation took 27.0512890816 seconds\n",
      "Theta: 25, score: 0.494692202912\n",
      "Best theta playlist: 25\n"
     ]
    }
   ],
   "source": [
    "best_theta_p_s1 = 25\n",
    "# results_gs_theta_playlist_exp1_s1 = grid_search_theta_playlist()\n",
    "exp1_s1_d = find_best_theta(results_gs_theta_playlist_exp1_s1)\n",
    "data_path = os.path.join(SCENARIO_DIR, 'exp1_s1_best_theta_p' + str(exp1_s1_d['theta_playlist']))\n",
    "np.savez(data_path, A=exp1_s1_d['a'], B=exp1_s1_d['b'])\n",
    "print 'Best theta playlist:', exp1_s1_d['theta_playlist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 110.356376171 seconds\n"
     ]
    }
   ],
   "source": [
    "exp1_s1_results = run_validation(data_path, exp1_s1_d['a'], exp1_s1_d['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_set</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_cat_out</th>\n",
       "      <td>0.506964</td>\n",
       "      <td>0.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_cluster</th>\n",
       "      <td>-0.174670</td>\n",
       "      <td>-0.181567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_genre</th>\n",
       "      <td>0.417569</td>\n",
       "      <td>0.451555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_in</th>\n",
       "      <td>63.381219</td>\n",
       "      <td>64.115534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_graph_dist_out</th>\n",
       "      <td>65.449713</td>\n",
       "      <td>65.678149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   test_set     random\n",
       "p_cat_out          0.506964   0.208200\n",
       "s_cluster         -0.174670  -0.181567\n",
       "s_genre            0.417569   0.451555\n",
       "s_graph_dist_in   63.381219  64.115534\n",
       "s_graph_dist_out  65.449713  65.678149"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_s1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = 100\n",
    "data_path = os.path.join(SCENARIO_DIR, 'exp1_s1_theta_p_' + str(theta))\n",
    "a_tmp, b_tmp = training_closure()(data_path, theta, 0.0, STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_tmp = run_validation(data_path, a_tmp, b_tmp, sample_size=0,\n",
    "                           with_sampled_playlists=False, score_playlist_cat_only=True, only_test_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "In this scenario, we have the playlist categories and the graph of playlists is well connected using both metadata and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR2 = os.path.join(EXPERIMENT_DIR, 'scenario2')\n",
    "if not os.path.exists(SCENARIO_DIR2):\n",
    "    os.mkdir(SCENARIO_DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playlist graph recommender\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 24.1706628799 seconds\n",
      "Theta: 1, score: 0.287420715778\n",
      "Validation took 23.7876780033 seconds\n",
      "Theta: 4, score: 0.470988802864\n",
      "Validation took 24.1222529411 seconds\n",
      "Theta: 7, score: 0.475221008159\n",
      "Validation took 24.54626894 seconds\n",
      "Theta: 10, score: 0.510715513653\n",
      "Validation took 23.8438780308 seconds\n",
      "Validation took 24.8922591209 seconds\n",
      "Validation took 24.2238149643 seconds\n",
      "Theta: 19, score: 0.560934709687\n",
      "Validation took 24.8920309544 seconds\n",
      "Validation took 25.6710669994 seconds\n",
      "Best theta playlist: 19\n"
     ]
    }
   ],
   "source": [
    "best_theta_p_s2 = 19\n",
    "def grid_search_theta_playlist_scenario2():\n",
    "    results = []\n",
    "    for theta in xrange(19, 50, 5):\n",
    "        d = {'theta_playlist': theta}\n",
    "        data_path = os.path.join(SCENARIO_DIR2, 'exp1_s2_theta_p_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta, 0.0, PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "# results_gs_theta_playlist_exp1_s2 = grid_search_theta_playlist_scenario2()\n",
    "exp1_s2_d = find_best_theta(results_gs_theta_playlist_exp1_s2)\n",
    "data_path = os.path.join(SCENARIO_DIR2, 'exp1_s2_best_theta_p' + str(exp1_s2_d['theta_playlist']))\n",
    "np.savez(data_path, A=exp1_s2_d['a'], B=exp1_s2_d['b'])\n",
    "print 'Best theta playlist:', exp1_s2_d['theta_playlist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 28.1861760616 seconds\n"
     ]
    }
   ],
   "source": [
    "exp1_s2_results = run_validation(data_path, exp1_s2_d['a'], exp1_s2_d['b'], sample_size=3, only_test_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_cat_out</th>\n",
       "      <th>s_cluster</th>\n",
       "      <th>s_genre</th>\n",
       "      <th>s_graph_dist_in</th>\n",
       "      <th>s_graph_dist_out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playlist_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Break Up</th>\n",
       "      <td>0.478125</td>\n",
       "      <td>-0.095833</td>\n",
       "      <td>0.433674</td>\n",
       "      <td>62.482516</td>\n",
       "      <td>62.248373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.307535</td>\n",
       "      <td>64.145665</td>\n",
       "      <td>67.081935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dance/House</th>\n",
       "      <td>0.622727</td>\n",
       "      <td>-0.089394</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>62.116141</td>\n",
       "      <td>61.492657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depression</th>\n",
       "      <td>0.442308</td>\n",
       "      <td>-0.052564</td>\n",
       "      <td>0.448716</td>\n",
       "      <td>63.057142</td>\n",
       "      <td>62.698203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip Hop</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.252187</td>\n",
       "      <td>62.178537</td>\n",
       "      <td>56.805685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Punk</th>\n",
       "      <td>0.158621</td>\n",
       "      <td>-0.162069</td>\n",
       "      <td>0.430259</td>\n",
       "      <td>63.048064</td>\n",
       "      <td>63.055532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhythm and Blues</th>\n",
       "      <td>0.848485</td>\n",
       "      <td>-0.203030</td>\n",
       "      <td>0.313366</td>\n",
       "      <td>63.391722</td>\n",
       "      <td>59.981659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.145556</td>\n",
       "      <td>0.481872</td>\n",
       "      <td>62.360381</td>\n",
       "      <td>63.301647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romantic</th>\n",
       "      <td>0.640625</td>\n",
       "      <td>-0.112500</td>\n",
       "      <td>0.422959</td>\n",
       "      <td>60.751138</td>\n",
       "      <td>62.530238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sleep</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.401975</td>\n",
       "      <td>65.263384</td>\n",
       "      <td>62.523771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   p_cat_out  s_cluster   s_genre  s_graph_dist_in  \\\n",
       "playlist_category                                                    \n",
       "Break Up            0.478125  -0.095833  0.433674        62.482516   \n",
       "Country             0.846154  -0.033333  0.307535        64.145665   \n",
       "Dance/House         0.622727  -0.089394  0.435268        62.116141   \n",
       "Depression          0.442308  -0.052564  0.448716        63.057142   \n",
       "Hip Hop             0.800000   0.021905  0.252187        62.178537   \n",
       "Punk                0.158621  -0.162069  0.430259        63.048064   \n",
       "Rhythm and Blues    0.848485  -0.203030  0.313366        63.391722   \n",
       "Rock                0.030000  -0.145556  0.481872        62.360381   \n",
       "Romantic            0.640625  -0.112500  0.422959        60.751138   \n",
       "Sleep               0.740000  -0.128571  0.401975        65.263384   \n",
       "\n",
       "                   s_graph_dist_out  \n",
       "playlist_category                    \n",
       "Break Up                  62.248373  \n",
       "Country                   67.081935  \n",
       "Dance/House               61.492657  \n",
       "Depression                62.698203  \n",
       "Hip Hop                   56.805685  \n",
       "Punk                      63.055532  \n",
       "Rhythm and Blues          59.981659  \n",
       "Rock                      63.301647  \n",
       "Romantic                  62.530238  \n",
       "Sleep                     62.523771  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_s2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_cat_out            0.560704\n",
       "s_cluster           -0.100095\n",
       "s_genre              0.392781\n",
       "s_graph_dist_in     62.879469\n",
       "s_graph_dist_out    62.171970\n",
       "dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1_s2_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agglomerate_results_per_category(data_path, 'p_cat_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "In this experiment we show the diversity of the recommended playlist. It augments if we augment the influence of the graph of songs. We use the STRIPPED playlist graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR2 = os.path.join(DUMP_DIR, 'experiment2')\n",
    "if not os.path.exists(EXPERIMENT_DIR2):\n",
    "    os.mkdir(EXPERIMENT_DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theta songs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid seach theta songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_theta_song():\n",
    "    results = []\n",
    "    for theta in xrange(1, 27, 3):\n",
    "        d = {'theta_song': theta}\n",
    "        data_path = os.path.join(EXPERIMENT_DIR2, 'exp2_theta_s_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta_playlists_nmf_playlist, theta, STRIPPED_PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "results_gs_theta_song = grid_search_theta_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerate results to compare the different theta songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog.reco_playlist_graph_only(None, SONGS, PLAYLISTS_TRAIN, song_id_key, 214, playlist_id_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLAYLISTS_TRAIN[PLAYLISTS_TRAIN.mix_id == 214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist + songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist_song = 10.\n",
    "theta_songs_nmf_playlist_song = 10.\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_song, B_nmf_playlist_song = training_closure()(data_path, \n",
    "                                                              theta_playlists_nmf_playlist_song,\n",
    "                                                              theta_songs_nmf_playlist_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song = recommend_and_save(data_path, A_nmf_playlist_song, B_nmf_playlist_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song - results_playlist_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist + songs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist_song2 = 10.\n",
    "theta_songs_nmf_playlist_song2 = 2.\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_song2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_song2, B_nmf_playlist_song2 = training_closure()(data_path, \n",
    "                                                                theta_playlists_nmf_playlist_song2, \n",
    "                                                                theta_songs_nmf_playlist_song2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 = recommend_and_save(data_path, A_nmf_playlist_song2, B_nmf_playlist_song2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 - results_nmf_playlist_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 - results_playlist_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2\n",
    "\n",
    "\n",
    "No playlist categories, we keep only the edges created by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripped_playlist_graph(g):\n",
    "    h = nx.Graph()\n",
    "    h.add_nodes_from(g.nodes(data=True))\n",
    "    counts = nx.get_edge_attributes(g, 'count')\n",
    "\n",
    "    cosine = lambda u, v, x: float(x) / (np.sqrt(g.node[u]['size']) * np.sqrt(g.node[v]['size']))\n",
    "    reweighted_attrs = [(k[0], k[1], cosine(k[0], k[1], v)) for k, v in counts.iteritems()]\n",
    "\n",
    "    h.add_weighted_edges_from(reweighted_attrs)\n",
    "\n",
    "    d = community.best_partition(h)\n",
    "    mod = community.modularity(d, h)\n",
    "    print 'Number of clusters: {}, Modularity: {}'.format(len(set(d.values())), mod)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR = os.path.join(DUMP_DIR, 'scenario2')\n",
    "if not os.path.exists(SCENARIO_DIR):\n",
    "    os.mkdir(SCENARIO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playlist only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(SCENARIO_DIR, 'playlist_graph_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_playlist_only_v2, B_playlist_only_v2 = training_closure()(data_path, \n",
    "                                                      theta_playlists_playlist_only, \n",
    "                                                      theta_songs_playlist_only,\n",
    "                                                      STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_playlist_only_v2 = recommend_and_save(data_path, A_playlist_only_v2, B_playlist_only_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_playlist_only_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist = 18 \n",
    "theta_songs_nmf_playlist = 0.0\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_v2, B_nmf_playlist_v2 = training_closure()(data_path, \n",
    "                                                          theta_playlists_nmf_playlist, \n",
    "                                                          theta_songs_nmf_playlist,\n",
    "                                                          STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2_mod = recommend_and_save(data_path, A_nmf_playlist_v2, B_nmf_playlist_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best nmf_playlist theta playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_theta = 12\n",
    "# 0.004379696413781331 \n",
    "last_diff = (results_nmf_playlist_v2 - results_playlist_only_v2)['p_cat_out']['test_set']\n",
    "\n",
    "best_A = A_nmf_playlist_v2\n",
    "best_B = B_nmf_playlist_v2\n",
    "for i, theta in enumerate(xrange(13, 20)):\n",
    "    theta_playlists_nmf_playlist = theta    \n",
    "    data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_' + str(i + 1))\n",
    "    A_nmf_playlist_v2, B_nmf_playlist_v2 = training_closure()(data_path, \n",
    "                                                          theta_playlists_nmf_playlist, \n",
    "                                                          theta_songs_nmf_playlist,\n",
    "                                                          STRIPPED_PLAYLIST_GRAPH_train)\n",
    "    results_nmf_playlist_v2 = recommend_and_save(data_path, A_nmf_playlist_v2, B_nmf_playlist_v2)\n",
    "    \n",
    "    diff = (results_nmf_playlist_v2 - results_playlist_only_v2)['p_cat_out']['test_set']\n",
    "    \n",
    "    if diff > last_diff:\n",
    "        last_diff = diff\n",
    "        best_theta = theta\n",
    "        best_A = A_nmf_playlist_v2\n",
    "        best_B = B_nmf_playlist_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v3 = recommend_and_save(data_path, best_A, best_B, STRIPPED_PLAYLIST_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist')\n",
    "np.savez(data_path, A=best_A, B=best_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output neighbors of a song in the song graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_id =  SONGS[SONGS.artist_name == 'The Beatles'].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_id = 545685 # yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = SONGS.reset_index()\n",
    "song_id = 1308  # on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sorted_neighbors(query, df, g, metadata=['artist_name', 'title', 'genre'], path=None):\n",
    "    s = df.reset_index()\n",
    "    neighbors = g[song_id]\n",
    "\n",
    "    res = []\n",
    "    for k, v in neighbors.iteritems():\n",
    "        res.append((k, v['weight']))\n",
    "        \n",
    "    t = list(reversed(sorted(res, key=operator.itemgetter(1))))\n",
    "    sorted_neighbors = map(lambda x: x[0], t)\n",
    "\n",
    "    res = s[s.index.isin(sorted_neighbors)][metadata]\n",
    "    res = res.reindex(sorted_neighbors, copy=True).reset_index(drop=True)    \n",
    "    res.index += 1\n",
    "    res2 = df.iloc[query][metadata]\n",
    "    \n",
    "    if path is not None:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(res.to_latex())\n",
    "            \n",
    "    return res, res2\n",
    "\n",
    "path = os.path.join(DATA_DIR, 'song_knn.tex')\n",
    "neighbors, query_song = get_sorted_neighbors(song_id, SONGS, SONG_GRAPH, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
