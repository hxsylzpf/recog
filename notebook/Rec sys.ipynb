{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank and Linear Spectral Matrix Completion for Playlist Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import itertools\n",
    "import random\n",
    "import community\n",
    "import IPython.utils.path\n",
    "import cPickle as pickle \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['axes.edgecolor'] = 'grey'\n",
    "mpl.rcParams['grid.color'] = '#66CCCC'\n",
    "mpl.rcParams['text.color'] = '#0EBFE9'\n",
    "mpl.rcParams['xtick.color'] = '#66CCCC'\n",
    "mpl.rcParams['ytick.color'] = '#66CCCC'\n",
    "mpl.rcParams['axes.labelcolor'] = '#0EBFE9'\n",
    "\n",
    "import recog \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reload(sys)  # Reload does the trick!\n",
    "# sys.setdefaultencoding('UTF8')\n",
    "\n",
    "# pd.options.display.encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.palettes import brewer\n",
    "bp.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mat(x, title, fig=(512, 200), cmap='Greys', reverse=False, nb_colors=9):\n",
    "    f1 = bp.figure(plot_width=fig[0], plot_height=fig[1], \n",
    "                   x_range=[0, x.shape[1]], y_range=[0, x.shape[0]])\n",
    "    \n",
    "\n",
    "    pal = brewer[cmap][nb_colors]\n",
    "    if reverse:\n",
    "        pal = pal[::-1]\n",
    "        \n",
    "    f1.image(image=[x], x=[0], y=[0], \n",
    "             dw=[x.shape[1]], dh=[x.shape[0]], palette=pal)\n",
    "    f1.title = title\n",
    "    f1.title_text_color = 'red'\n",
    "    f1.title_text_font_style = 'bold'\n",
    "    bp.show(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(IPython.utils.path.get_home_dir(), 'data/aotmv2/')\n",
    "DATA_DIR = os.path.join( IPython.utils.path.get_home_dir(), 'local/aotmv2/')\n",
    "print 'Data directory:', DATA_DIR\n",
    "\n",
    "DATASET_NAME = 'aotm'\n",
    "MAX_PROCESS = 8\n",
    "song_id_key = 'aotm_id'\n",
    "playlist_id_key = 'mix_id'\n",
    "playlist_cat_key = 'playlist_category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FULL_SONGS = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_songs.h5'), 'data')\n",
    "FULL_SONGS.rename(columns={'temporal_echonest_features': 'ten'}, inplace=True)\n",
    "FULL_PLAYLISTS = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_playlists.h5'), 'data')\n",
    "FULL_MIXES = pd.read_hdf(os.path.join(DATA_DIR, DATASET_NAME + '_mixes.h5'), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features only from data\n",
    "to_remove = set(['title', 'artist_name', 'genre', 'top_genres', 'terms', \n",
    "                 'release', 'key', 'mode', 'genre_topics', 'genre_topic', 'ncut_id'])\n",
    "columns = set(FULL_SONGS.columns.tolist())\n",
    "feat_col = list(columns - to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create smaller dataset from AOTM data\n",
    "\n",
    "Here we remove ambiguous plyalist categories, we also verify that there are a sufficient number of playlists in each category. Each playlist is composed of \"popular songs\", (songs seen at least in a certain amount of playlists), and is not too short not too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min_playlists = 70\n",
    "min_playlists = 100\n",
    "# min_playlist_size = 8\n",
    "min_playlist_size = 5\n",
    "max_playlist_size = 20\n",
    "min_popularity = 5\n",
    "\n",
    "to_remove = ['Mixed Genre', 'Theme', 'Single Artist', 'Alternating DJ', 'Mixed', 'Cover', 'Narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove ambiguous categories\n",
    "FILT_MIXES = FULL_MIXES[~FULL_MIXES.playlist_category.isin(to_remove)]\n",
    "# Remove too short or too long playlists\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES['size'].between(min_playlist_size, max_playlist_size)]\n",
    "\n",
    "# Filter popular songs\n",
    "good_playlist_categories = np.unique(FILT_MIXES.playlist_category.values)\n",
    "FILT_PLAYLISTS = FULL_PLAYLISTS[FULL_PLAYLISTS[playlist_cat_key].isin(good_playlist_categories)]\n",
    "song_popularity_hist = FILT_PLAYLISTS.aotm_id.value_counts()\n",
    "good_songs = song_popularity_hist[song_popularity_hist >= min_popularity].index.values\n",
    "FILT_MIXES[song_id_key] = FILT_MIXES[song_id_key].apply(lambda x: list((set(x) & set(good_songs))))\n",
    "FILT_MIXES['size'] = FILT_MIXES[song_id_key].apply(len)\n",
    "\n",
    "# Refilter size of playlists\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES['size'].between(min_playlist_size, max_playlist_size)]\n",
    "# Keep a sufficient number of playlist in each category\n",
    "p_hist = FILT_MIXES[playlist_cat_key].value_counts()\n",
    "P_CATEGORIES = p_hist.index[np.where(p_hist > min_playlists)].values\n",
    "FILT_MIXES = FILT_MIXES[FILT_MIXES[playlist_cat_key].isin(P_CATEGORIES)]\n",
    "\n",
    "# Update the list of valid songs since we removed some playlists\n",
    "good_songs = np.unique(list(itertools.chain(*list(FILT_MIXES[song_id_key].values))))\n",
    "FILT_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[playlist_id_key].isin(FILT_MIXES.index.values)]\n",
    "FILT_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[song_id_key].isin(good_songs)]\n",
    "\n",
    "# Keep only valid song and features in playlists\n",
    "FILT_SONGS = FULL_SONGS[FULL_SONGS.index.isin(good_songs)].sort('genre')\n",
    "FILT_FEAT = FILT_SONGS[feat_col]\n",
    "\n",
    "print 'Number of playlists:', len(FILT_MIXES)\n",
    "print 'Number of songs:', len(FILT_SONGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILT_MIXES[playlist_cat_key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create evenly sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_keep = ['Romantic', 'Depression', 'Break Up', 'Sleep',\n",
    "           'Punk', 'Country', 'Hip Hop', 'Dance/House', 'Rock', 'Rhythm and Blues']\n",
    "\n",
    "P_CATEGORIES = to_keep\n",
    "\n",
    "cat_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MINI_MIXES = FILT_MIXES[FILT_MIXES.playlist_category.isin(to_keep)]\n",
    "\n",
    "tmp = MINI_MIXES.reset_index().groupby(playlist_cat_key).agg({playlist_id_key: lambda x: random.sample(x, cat_size)})\n",
    "good_mixes = np.unique(list(itertools.chain(*list(tmp[playlist_id_key].values))))\n",
    "\n",
    "MINI_MIXES = MINI_MIXES[MINI_MIXES.index.isin(good_mixes)]\n",
    "# sample_idx = random.sample(MINI_MIXES.index, len(MINI_MIXES) // sample_factor)\n",
    "# MINI_MIXES = MINI_MIXES[MINI_MIXES.index.isin(sample_idx)]\n",
    "# Update the list of valid songs since we removed some playlists\n",
    "good_songs = np.unique(list(itertools.chain(*list(MINI_MIXES[song_id_key].values))))\n",
    "MINI_PLAYLISTS = FILT_PLAYLISTS[FILT_PLAYLISTS[playlist_id_key].isin(MINI_MIXES.index.values)]\n",
    "MINI_PLAYLISTS = MINI_PLAYLISTS[MINI_PLAYLISTS[song_id_key].isin(good_songs)]\n",
    "\n",
    "# Keep only valid song and features in playlists\n",
    "MINI_SONGS = FILT_SONGS[FILT_SONGS.index.isin(good_songs)].sort('genre')\n",
    "MINI_FEAT = MINI_SONGS[feat_col]\n",
    "\n",
    "print 'Number of playlists:', len(MINI_MIXES)\n",
    "print 'Number of songs:', len(MINI_SONGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MINI_MIXES[playlist_cat_key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIXES = MINI_MIXES\n",
    "FEAT = MINI_FEAT\n",
    "PLAYLISTS = MINI_PLAYLISTS\n",
    "SONGS = MINI_SONGS\n",
    "DATASET_VERSION = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MIXES = FILT_MIXES\n",
    "# FEAT = FILT_FEAT\n",
    "# PLAYLISTS = FILT_PLAYLISTS\n",
    "# SONGS = FILT_SONGS\n",
    "# SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "# DATASET_VERSION = 'filt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DUMP_DIR = os.path.join(DATA_DIR, 'dump_' + DATASET_VERSION + '/')\n",
    "\n",
    "if not os.path.exists(DUMP_DIR):\n",
    "    os.mkdir(DUMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare graphs\n",
    "\n",
    "First, create train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixes_train_idx, mixes_test_idx = train_test_split(MIXES.index.values, train_size=train_set_size)\n",
    "mixes_train_idx, mixes_test_idx = sorted(mixes_train_idx), sorted(mixes_test_idx)\n",
    "\n",
    "MIXES_train = MIXES[MIXES.index.isin(mixes_train_idx)]\n",
    "MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]\n",
    "PLAYLISTS_train = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_train_idx)]\n",
    "\n",
    "songs_train_idx = np.unique(list(itertools.chain(*list(MIXES_train[song_id_key].values))))\n",
    "songs_test_idx = np.unique(list(itertools.chain(*list(MIXES_test[song_id_key].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create song graph\n",
    "\n",
    "To keep the same number of nodes, we create the full song graph and we remove edges not in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SONG_GRAPH, SONGS = recog.graph.create_song_graph(FEAT, SONGS, 5)\n",
    "SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "print nx.info(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_SONGS = nx.to_numpy_matrix(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample = W_SONGS[2300:3500, 2300:3500]\n",
    "sample = W_SONGS\n",
    "sample = (sample > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Song graph', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_song_graph_partitions_' + str(SONG_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute all shortest path between songs for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pairs_distance = nx.all_pairs_dijkstra_path_length(SONG_GRAPH, weight='dist')\n",
    "end = time.time()\n",
    "print 'Created in:', end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(pairs_distance, open(os.path.join(DUMP_DIR, 'song_pairs_distance.pickle'), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create playlist graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLAYLIST_GRAPH_train, MIXES_train, PLAYLISTS_train = recog.graph.create_playlist_graph(MIXES_train.copy(), PLAYLISTS_train, playlist_id_key, song_id_key, \n",
    "                                                       'playlist_category', 0.3, 0.2)\n",
    "print nx.info(PLAYLIST_GRAPH_train)\n",
    "\n",
    "# MIXES_train = MIXES[MIXES.index.isin(mixes_train_idx)]\n",
    "# MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_PLAYLISTS = nx.to_numpy_matrix(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = (W_PLAYLISTS > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Playlist graph', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_playlist_graph_partitions_' + str(PLAYLIST_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playlist graph without categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripped_playlist_graph(g):\n",
    "    h = nx.Graph()\n",
    "    h.add_nodes_from(g.nodes(data=True))\n",
    "    counts = nx.get_edge_attributes(g, 'count')\n",
    "\n",
    "    cosine = lambda u, v, x: float(x) / (np.sqrt(g.node[u]['size']) * np.sqrt(g.node[v]['size']))\n",
    "    reweighted_attrs = [(k[0], k[1], cosine(k[0], k[1], v)) for k, v in counts.iteritems()]\n",
    "\n",
    "    h.add_weighted_edges_from(reweighted_attrs)\n",
    "\n",
    "    d = community.best_partition(h)\n",
    "    mod = community.modularity(d, h)\n",
    "    print 'Number of clusters: {}, Modularity: {}'.format(len(set(d.values())), mod)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_PLAYLISTS_train = nx.to_numpy_matrix(STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = (W_PLAYLISTS_train > 0).astype(np.float)\n",
    "recog.plot_factor_mat(sample, 'Adjacency matrix for Playlist graph train', 'Blues')\n",
    "# plot_mat(W_SONGS.todense(), 'Song graph ncut', fig=(512, 512))\n",
    "fig1 = plt.gcf()\n",
    "ax = plt.gca()\n",
    "fig1.frameon = False\n",
    "ax.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "fig_path = os.path.join(DUMP_DIR, 'sample_playlist_graph_train_partitions_' + str(PLAYLIST_GRAPH.graph['partitions']) + '.png')\n",
    "fig1.savefig(fig_path, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIXES_train.groupby('cluster_id')['playlist_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create C matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C_train = recog.create_recommendation_matrix(MIXES_train, SONGS.index,\n",
    "                                     playlist_id_key, DATASET_NAME, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog.plot_factor_mat(C_train.toarray())\n",
    "# plot_mat(C_train.toarray(), 'C', (512, 512))\n",
    "print 'Sparsity ratio:', C_train.nnz / float(C_train.shape[0] * C_train.shape[1])\n",
    "print C_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump(outdir):\n",
    "    # Write graphs\n",
    "    nx.write_gpickle(SONG_GRAPH, os.path.join(outdir, 'song_graph.gpickle'))\n",
    "#     nx.write_gpickle(SONG_GRAPH_train, os.path.join(outdir, 'song_graph_train.gpickle'))\n",
    "#     nx.write_gpickle(PLAYLIST_GRAPH, os.path.join(outdir, 'playlist_graph.gpickle'))\n",
    "    nx.write_gpickle(PLAYLIST_GRAPH_train, os.path.join(outdir, 'playlist_graph_train.gpickle'))\n",
    "    \n",
    "    # Write data\n",
    "    store = pd.HDFStore(os.path.join(outdir, 'data.h5'))\n",
    "    store['songs'] = SONGS\n",
    "    store['mixes'] = MIXES\n",
    "    store['playlists'] = PLAYLISTS\n",
    "    store.close()\n",
    "\n",
    "    matlab_export_path = os.path.join(outdir, 'recog_real_data.mat')\n",
    "    matlab_data = dict()\n",
    "\n",
    "#     matlab_data['C'] = C\n",
    "    matlab_data['C_train'] = C_train\n",
    "#     matlab_data['songs_train'] = songs_train_idx.tolist()\n",
    "#     matlab_data['songs_test'] = songs_test_idx.tolist()\n",
    "    matlab_data['mixes_train'] = mixes_train_idx\n",
    "    matlab_data['mixes_test'] = mixes_test_idx\n",
    "\n",
    "    sp.io.savemat(matlab_export_path, matlab_data)\n",
    "    print 'Dump data to:', outdir\n",
    "    \n",
    "dump(DUMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(outdir):    \n",
    "    if not os.path.exists(outdir):\n",
    "        print 'Error folder does not exists'\n",
    "        return\n",
    "\n",
    "    song_graph = nx.read_gpickle(os.path.join(outdir, 'song_graph.gpickle'))\n",
    "#     song_graph_train = nx.read_gpickle(os.path.join(outdir, 'song_graph_train.gpickle'))\n",
    "#     playlist_graph = nx.read_gpickle(os.path.join(outdir, 'playlist_graph.gpickle'))\n",
    "    playlist_graph_train = nx.read_gpickle(os.path.join(outdir, 'playlist_graph_train.gpickle'))\n",
    "    \n",
    "    store = pd.HDFStore(os.path.join(outdir, 'data.h5'))\n",
    "    songs = store['songs']\n",
    "    mixes = store['mixes']\n",
    "    playlists = store['playlists']\n",
    "    store.close()\n",
    "\n",
    "    matlab_export_path = os.path.join(outdir, 'recog_real_data.mat')\n",
    "    data = sp.io.loadmat(matlab_export_path)\n",
    "    \n",
    "#     c = data['C']\n",
    "    c_train = data['C_train']\n",
    "#     songs_train_idx = data['songs_train'].tolist()[0]\n",
    "#     songs_test_idx = data['songs_test'].tolist()[0]\n",
    "    mixes_train_idx = data['mixes_train'].tolist()[0]\n",
    "    mixes_test_idx = data['mixes_test'].tolist()[0]\n",
    "\n",
    "    return songs, mixes, playlists, song_graph, playlist_graph_train, c_train, mixes_train_idx, mixes_test_idx\n",
    "    \n",
    "\n",
    "DATASET_VERSION = 'medium'\n",
    "DUMP_DIR = os.path.join(DATA_DIR, 'dump_' + DATASET_VERSION + '/')\n",
    "    \n",
    "SONGS, MIXES, PLAYLISTS, SONG_GRAPH, PLAYLIST_GRAPH_train, C_train, mixes_train_idx, mixes_test_idx = load(DUMP_DIR)\n",
    "FEAT = SONGS[feat_col]\n",
    "SONG_TO_IDX = dict(zip(SONGS.index.values, itertools.count()))\n",
    "MIXES_test = MIXES[MIXES.index.isin(mixes_test_idx)]\n",
    "pairs_distance = None\n",
    "PLAYLISTS_train = PLAYLISTS[PLAYLISTS[playlist_id_key].isin(mixes_train_idx)]\n",
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if needed\n",
    "pairs_distance = pickle.load(open(os.path.join(DUMP_DIR, 'song_pairs_distance.pickle'), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rank = len(P_CATEGORIES)\n",
    "rank = 10  # number of clusters of song graph\n",
    "playlist_size = 30\n",
    "sample_size = 7\n",
    "nb_sampled_playlists = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agglomerate_results_per_category(data_path, key):\n",
    "    path = data_path + '.h5'\n",
    "    store = pd.HDFStore(path)\n",
    "    random = store['results_random'][key]\n",
    "    \n",
    "    test_set = store['results_test_per_category'][key]\n",
    "    sampled = store['results_sampled'][key]\n",
    "    \n",
    "    res = pd.DataFrame(index=random.index)\n",
    "    res['Random'] = random\n",
    "    res['Test set'] = test_set\n",
    "    res['Sampled'] = sampled\n",
    "    store.close()\n",
    "    \n",
    "    res.index.name = 'Playlist category'\n",
    "    \n",
    "    out = data_path + '_agg_' + key + '.tex'\n",
    "    res.to_latex(out)\n",
    "    return res\n",
    "\n",
    "\n",
    "def training_closure():\n",
    "    def inner(data_path, theta_playlists, theta_songs, playlist_graph):  # stripped or normal\n",
    "        return recog.proximal_training(C_train, playlist_graph, SONG_GRAPH, rank,\n",
    "                                       theta_tv_a=theta_playlists,\n",
    "                                       theta_tv_b=theta_songs,\n",
    "                                       data_path=data_path,\n",
    "                                       verbose=1)\n",
    "    return inner\n",
    "\n",
    "\n",
    "def recommend_and_save(data_path, A, B):\n",
    "    start = time.time()\n",
    "    results_test = recog.test_playlists(MIXES_test, PLAYLISTS, SONGS, A, B, playlist_size, \n",
    "                                        SONG_TO_IDX, song_id_key, playlist_cat_key,\n",
    "                                        pairs_distance=pairs_distance, pgraph_full=None) \n",
    "    mean_results_test = results_test.groupby('p_' + playlist_cat_key).mean()\n",
    "    results_sampled, results_random = recog.sampled_vs_random(nb_sampled_playlists, P_CATEGORIES, PLAYLISTS, SONGS, \n",
    "                                        sample_size, A, B, playlist_size, SONG_TO_IDX, song_id_key, \n",
    "                                              playlist_cat_key, pairs_distance=pairs_distance)\n",
    "    res = [mean_results_test.mean(), results_sampled.mean(), results_random.mean()]\n",
    "    results = pd.DataFrame(res)\n",
    "    results.set_index(pd.Index(['test_set', 'sampled', 'random']), inplace=True)\n",
    "    \n",
    "    path = data_path + '.h5'\n",
    "    store = pd.HDFStore(path)\n",
    "    store['results_test'] = results_test\n",
    "    store['results_sampled'] = results_sampled\n",
    "    store['results_random'] = results_random\n",
    "    store['results_test_per_category'] = mean_results_test\n",
    "    store.close()\n",
    "    print 'Done in {} seconds'.format(time.time() - start)\n",
    "    return results\n",
    "\n",
    "\n",
    "def rec_sys_factory(method=0):  # add common params here\n",
    "    if method == 0:\n",
    "        return recog.recommend\n",
    "    else if method == 1:\n",
    "        return recog.recommend_playlist_graph_only\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def create_sampled_mix_df(playlist_df, sample_size, nb_playlists, p_category):\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO, create mix df if sampled from playlist or random and generated scores\n",
    "def scores_from_mix_df(mix_df, rec_method):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average pairwise distance of song graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = nx.get_edge_attributes(SONG_GRAPH, 'dist')\n",
    "\n",
    "res = sum(map(lambda x: x[1], distances.items()))\n",
    "res /= len(distances)\n",
    "\n",
    "print 'Average distance on the song graph:', res\n",
    "    \n",
    "print 'Diameter:', nx.diameter(SONG_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "Here we set theta_song to 0 and compare our model to the random case or using a simple playlist recommender system.\n",
    "\n",
    "We designed two scenarii with a playlist graph only created with cosine similarity, the second scenario also add the metadata.\n",
    "\n",
    "We test different cases:\n",
    "\n",
    "- NMF only $\\theta_p = \\theta_s = 0$\n",
    "- NMF + playlist graph compared to a different rec sys using only playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = os.path.join(DUMP_DIR, 'experiment1')\n",
    "if not os.path.exists(EXPERIMENT_DIR):\n",
    "    os.mkdir(EXPERIMENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_only = 0\n",
    "theta_songs_nmf_only = 0\n",
    "data_path = os.path.join(EXPERIMENT_DIR, 'nmf_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_only, B_nmf_only = training_closure()(data_path, \n",
    "                                            theta_playlists_nmf_only,\n",
    "                                            theta_songs_nmf_only, \n",
    "                                            STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_only = recommend_and_save(data_path, A_nmf_only, B_nmf_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_cat_in</th>\n",
       "      <th>p_cat_out</th>\n",
       "      <th>s_cluster_in</th>\n",
       "      <th>s_cluster_out</th>\n",
       "      <th>s_genre</th>\n",
       "      <th>s_graph_dist_in</th>\n",
       "      <th>s_graph_dist_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_set</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197329</td>\n",
       "      <td>0.347708</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.396629</td>\n",
       "      <td>63.028296</td>\n",
       "      <td>64.461499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampled</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.350429</td>\n",
       "      <td>0.248567</td>\n",
       "      <td>0.371115</td>\n",
       "      <td>63.108911</td>\n",
       "      <td>64.373068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.157214</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.339143</td>\n",
       "      <td>0.252133</td>\n",
       "      <td>0.302794</td>\n",
       "      <td>63.517827</td>\n",
       "      <td>64.369289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_cat_in  p_cat_out  s_cluster_in  s_cluster_out   s_genre  \\\n",
       "test_set  1.000000   0.197329      0.347708       0.253600  0.396629   \n",
       "sampled   1.000000   0.174000      0.350429       0.248567  0.371115   \n",
       "random    0.157214   0.144200      0.339143       0.252133  0.302794   \n",
       "\n",
       "          s_graph_dist_in  s_graph_dist_out  \n",
       "test_set        63.028296         64.461499  \n",
       "sampled         63.108911         64.373068  \n",
       "random          63.517827         64.369289  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nmf_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1\n",
    "\n",
    "In this scenario no playlist categories are given, we create a playlist similarity graph only using cosine similarity. This is the normal case (Spotify, Deezer, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR = os.path.join(EXPERIMENT_DIR, 'scenario1')\n",
    "if not os.path.exists(SCENARIO_DIR):\n",
    "    os.mkdir(SCENARIO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playlist graph recommender\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our recommender system\n",
    "\n",
    "Find best theta from grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_theta_playlist():\n",
    "    results = []\n",
    "    for theta in xrange(1, 27, 3):\n",
    "        d = {'theta_playlist': theta}\n",
    "        data_path = os.path.join(SCENARIO_DIR, 'exp1_s1_theta_p_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta, 0.0, STRIPPED_PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "results_gs_theta_playlist_exp1_s1 = grid_search_theta_playlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO CHANGE, best a and b and change recommend method\n",
    "results_exp1_s1 = recommend_and_save(data_path, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_exp1_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "\n",
    "In this scenario, we have the playlist categories and the graph of playlists is well connected using both metadata and cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR2 = os.path.join(EXPERIMENT_DIR, 'scenario2')\n",
    "if not os.path.exists(SCENARIO_DIR2):\n",
    "    os.mkdir(SCENARIO_DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playlist graph recommender\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_search_theta_playlist_scenario2():\n",
    "    results = []\n",
    "    for theta in xrange(1, 27, 3):\n",
    "        d = {'theta_playlist': theta}\n",
    "        data_path = os.path.join(SCENARIO_DIR2, 'exp1_s2_theta_p_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta, 0.0, PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "results_gs_theta_playlist_exp1_s2 = grid_search_theta_playlist_scenario2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO CHANGE\n",
    "results_exp1_s2 = recommend_and_save(data_path, A_nmf_playlist2, B_nmf_playlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_exp1_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agglomerate_results_per_category(data_path, 'p_cat_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "In this experiment we show the diversity of the recommended playlist. It augments if we augment the influence of the graph of songs. We use the STRIPPED playlist graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR2 = os.path.join(DUMP_DIR, 'experiment2')\n",
    "if not os.path.exists(EXPERIMENT_DIR2):\n",
    "    os.mkdir(EXPERIMENT_DIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theta songs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid seach theta songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_theta_song():\n",
    "    results = []\n",
    "    for theta in xrange(1, 27, 3):\n",
    "        d = {'theta_song': theta}\n",
    "        data_path = os.path.join(EXPERIMENT_DIR2, 'exp2_theta_s_' + str(theta))\n",
    "        d['data_path'] = data_path\n",
    "        a, b = training_closure()(data_path, theta_playlists_nmf_playlist, theta, STRIPPED_PLAYLIST_GRAPH_train)\n",
    "        d['a'] = a\n",
    "        d['b'] = b\n",
    "        results.append(d)\n",
    "    return results\n",
    "\n",
    "results_gs_theta_song = grid_search_theta_song()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerate results to compare the different theta songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recog.reco_playlist_graph_only(None, SONGS, PLAYLISTS_TRAIN, song_id_key, 214, playlist_id_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PLAYLISTS_TRAIN[PLAYLISTS_TRAIN.mix_id == 214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist + songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist_song = 10.\n",
    "theta_songs_nmf_playlist_song = 10.\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_song, B_nmf_playlist_song = training_closure()(data_path, \n",
    "                                                              theta_playlists_nmf_playlist_song,\n",
    "                                                              theta_songs_nmf_playlist_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song = recommend_and_save(data_path, A_nmf_playlist_song, B_nmf_playlist_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song - results_playlist_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist + songs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist_song2 = 10.\n",
    "theta_songs_nmf_playlist_song2 = 2.\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_song2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_song2, B_nmf_playlist_song2 = training_closure()(data_path, \n",
    "                                                                theta_playlists_nmf_playlist_song2, \n",
    "                                                                theta_songs_nmf_playlist_song2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 = recommend_and_save(data_path, A_nmf_playlist_song2, B_nmf_playlist_song2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 - results_nmf_playlist_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_song2 - results_playlist_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2\n",
    "\n",
    "\n",
    "No playlist categories, we keep only the edges created by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stripped_playlist_graph(g):\n",
    "    h = nx.Graph()\n",
    "    h.add_nodes_from(g.nodes(data=True))\n",
    "    counts = nx.get_edge_attributes(g, 'count')\n",
    "\n",
    "    cosine = lambda u, v, x: float(x) / (np.sqrt(g.node[u]['size']) * np.sqrt(g.node[v]['size']))\n",
    "    reweighted_attrs = [(k[0], k[1], cosine(k[0], k[1], v)) for k, v in counts.iteritems()]\n",
    "\n",
    "    h.add_weighted_edges_from(reweighted_attrs)\n",
    "\n",
    "    d = community.best_partition(h)\n",
    "    mod = community.modularity(d, h)\n",
    "    print 'Number of clusters: {}, Modularity: {}'.format(len(set(d.values())), mod)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRIPPED_PLAYLIST_GRAPH_train = stripped_playlist_graph(PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIO_DIR = os.path.join(DUMP_DIR, 'scenario2')\n",
    "if not os.path.exists(SCENARIO_DIR):\n",
    "    os.mkdir(SCENARIO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playlist only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(SCENARIO_DIR, 'playlist_graph_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_playlist_only_v2, B_playlist_only_v2 = training_closure()(data_path, \n",
    "                                                      theta_playlists_playlist_only, \n",
    "                                                      theta_songs_playlist_only,\n",
    "                                                      STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_playlist_only_v2 = recommend_and_save(data_path, A_playlist_only_v2, B_playlist_only_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_playlist_only_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF + playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_playlists_nmf_playlist = 18 \n",
    "theta_songs_nmf_playlist = 0.0\n",
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_nmf_playlist_v2, B_nmf_playlist_v2 = training_closure()(data_path, \n",
    "                                                          theta_playlists_nmf_playlist, \n",
    "                                                          theta_songs_nmf_playlist,\n",
    "                                                          STRIPPED_PLAYLIST_GRAPH_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2_mod = recommend_and_save(data_path, A_nmf_playlist_v2, B_nmf_playlist_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v2_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best nmf_playlist theta playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_theta = 12\n",
    "# 0.004379696413781331 \n",
    "last_diff = (results_nmf_playlist_v2 - results_playlist_only_v2)['p_cat_out']['test_set']\n",
    "\n",
    "best_A = A_nmf_playlist_v2\n",
    "best_B = B_nmf_playlist_v2\n",
    "for i, theta in enumerate(xrange(13, 20)):\n",
    "    theta_playlists_nmf_playlist = theta    \n",
    "    data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist_' + str(i + 1))\n",
    "    A_nmf_playlist_v2, B_nmf_playlist_v2 = training_closure()(data_path, \n",
    "                                                          theta_playlists_nmf_playlist, \n",
    "                                                          theta_songs_nmf_playlist,\n",
    "                                                          STRIPPED_PLAYLIST_GRAPH_train)\n",
    "    results_nmf_playlist_v2 = recommend_and_save(data_path, A_nmf_playlist_v2, B_nmf_playlist_v2)\n",
    "    \n",
    "    diff = (results_nmf_playlist_v2 - results_playlist_only_v2)['p_cat_out']['test_set']\n",
    "    \n",
    "    if diff > last_diff:\n",
    "        last_diff = diff\n",
    "        best_theta = theta\n",
    "        best_A = A_nmf_playlist_v2\n",
    "        best_B = B_nmf_playlist_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v3 = recommend_and_save(data_path, best_A, best_B, STRIPPED_PLAYLIST_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_nmf_playlist_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(SCENARIO_DIR, 'nmf_playlist')\n",
    "np.savez(data_path, A=best_A, B=best_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output neighbors of a song in the song graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_id =  SONGS[SONGS.artist_name == 'The Beatles'].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_id = 545685 # yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = SONGS.reset_index()\n",
    "song_id = 1308  # on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sorted_neighbors(query, df, g, metadata=['artist_name', 'title', 'genre'], path=None):\n",
    "    s = df.reset_index()\n",
    "    neighbors = g[song_id]\n",
    "\n",
    "    res = []\n",
    "    for k, v in neighbors.iteritems():\n",
    "        res.append((k, v['weight']))\n",
    "        \n",
    "    t = list(reversed(sorted(res, key=operator.itemgetter(1))))\n",
    "    sorted_neighbors = map(lambda x: x[0], t)\n",
    "\n",
    "    res = s[s.index.isin(sorted_neighbors)][metadata]\n",
    "    res = res.reindex(sorted_neighbors, copy=True).reset_index(drop=True)    \n",
    "    res.index += 1\n",
    "    res2 = df.iloc[query][metadata]\n",
    "    \n",
    "    if path is not None:\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(res.to_latex())\n",
    "            \n",
    "    return res, res2\n",
    "\n",
    "path = os.path.join(DATA_DIR, 'song_knn.tex')\n",
    "neighbors, query_song = get_sorted_neighbors(song_id, SONGS, SONG_GRAPH, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
